# Машинное обучение "без учителя". Задача кластеризации. 

В практических примерах ниже показано:   

* как пользоваться инструментами визуального анализа для предварительной интерпретации кластеров 
* как проводить кластерный анализ 
* как строить прогноз принадлежности к кластерам новых наблюдений
* как оценивать точность кластеризации

*Модели*: иерархический и неиерархический кластерный анализ

*Данные*: load_iris

Данные в примере:
* **sepal length (cm)** - длина чашелистика (см)
* **sepal width (cm)** - ширина чашелистика (см)
* **petal length (cm)** - длина лепестка (см)
* **petal width (cm)** - ширина лепестка (см)

Задача состоит в разделении ирисов на группы в зависимости от  показателей(sepal length (cm) petal length (cm))

![image](https://user-images.githubusercontent.com/91901972/223779743-d96d8927-c493-4114-a20a-c712b0f8a008.png)


![image](https://user-images.githubusercontent.com/91901972/223772875-61fa8aa0-77f0-49fd-b03d-97e0eb0ff500.png)

В нашем примере наблюдения визуально сгруппированы на 4 группы. Тем не менее, рассмотрим метод для определения наилучшего количества кластеров.

#### Определение оптимального количества кластеров для метода локтя

Здесь $w_{ij}$ = 1, если наблюдение относится к кластеру $j$ и 0 в противоположном случае, а $m_i$ - центроид кластера.

Одна из основных трудностей в обучении без учителя состоит в том, что мы не знаем точного ответа. В нашем наборе данных нет 
установленных данных о метках классов, поэтому для количественного определения качества кластеризации нам нужно использовать внутренние метрики - такие как внутрикластерная **SSE** (искажение или инерция):
$$SSE = \sum\limits_{i=1}^n\sum\limits_{j=1}^kw_{ij}(x_i - m_i)^2$$

Основываясь на внутрикластерной SSE, мы можем применить графический инструмент,
так называемый метод локтя, для оценки оптимального числа k кластеров для поставленной задачи. 
Интуитивно мы можем сказать, что если k увеличивается, то искажение уменьшается. 
Это вызвано тем, что образцы будут ближе к центроидам, которым они назначены. 
В основе метода локтя лежит идея, которая состоит в том, чтобы идентифицировать значение k в точке,
где искажение начинает увеличиваться быстрее всего, что станет понятнее, если мы построим график искажения для разных значений k.

![image](https://user-images.githubusercontent.com/91901972/223774216-62962e36-4cfc-4c51-b930-17dcc2b8ff47.png)

Как видно на следующем выше графике, локоть расположен в k = 4, что свидетельствует о том, что k = 4 является хорошим выбором для этого набора данных.

![image](https://user-images.githubusercontent.com/91901972/223774948-e3a52223-a045-4967-b25c-7b38848e21e3.png)

Тем не менее, визуальный анализ говорит о наличии 3 различных групп. Сделаем и такое построение:

![image](https://user-images.githubusercontent.com/91901972/223775657-8358dea6-bd4f-440f-b0f1-82570e11df41.png)

Теперь видим, что каждая группа точек покрашена в цвет соответствующего кластера, а центроиды расположены внутри множества точек. Тем не менее, попробуем оценить качество кластеризации в обоих вариантах.

#### Количественная оценка качества кластеризации

Внутренняя метрика для оценки качества кластеризации (наряду с **SSE**) представлена силуэтным анализом
Силуэтный анализ может использоваться в качестве графического инструмента для построения графика меры плотности группировки образцов в кластерах. 
Чтобы вычислить силуэтный коэффициент наблюдения в нашем наборе данных, можно применить следующие три шага. 
1. Вычислить *внутриклассовую связность* $a_i$ как среднее расстояние между наблюдением и другими точками кластера
2. Вычислить *межкластерное разделение* $b_i$ от следующего ближайшего кластера как среднее расстояние между наблюдением $х_i$ и всеми наблюдениями в ближайшем кластере
3. Вычислить *силуэт* $s_i$:
$$s_i = (b_i - a_i)/\max(b_i,a_i).$$

$s_i$ принимает значения в диапазоне $[-1, 1]$. Идеальное совпадение - когда $s_i = 1.$

Посчитаем для k=3 кластеров:

![image](https://user-images.githubusercontent.com/91901972/223778451-19fb42c9-731c-4b14-9812-cdec84b23ed5.png)

Средний коэффициент силуэта весьма близок к 0.6 , что говорит о относительным качестве кластеризации.
Если силуэты зрительно значительно отличаются друг от друга по длине, то это является признаком *субоптимальной* кластеризации. Как правило, в этом случае центроиды кластеров стоят отдельно от множества точек кластера. 
Посчитаем средний силуэтный коэффициент для кластеризации $k=4$. 

Средний коэффициент силуэта --  0.5645593160995662

Его значение немного ниже, чем в предыдущем случае. Формально $k=3$ - более оптимальное разбиение.

#### Сравнение результатов на обучающей и тестовой выборке
Посмотрим, как прогнозировать новых наблюдений принадлежность к кластерам, построенным по обучающим данным. Сравним значения средних силуэтных коэффициентов.

В обучающей выборке - 80% исходных наблюдений.

Добавляем к выборке дополнительный показатель.

![image](https://user-images.githubusercontent.com/91901972/223780228-b6b36774-f1ad-439e-a1fa-d21794951e23.png)

![image](https://user-images.githubusercontent.com/91901972/223781364-1a2e1e7a-1b31-452b-b48d-d0ba85560543.png)

Как видно на следующем выше графике, заметных изменений не обнаружилось.

Обучаем алгоритм и считаем средний силуэтный коэффициент.

Средний коэффициент силуэта --  0.5477858909230147

Применяем модель к новым данным. Значение среднего силуэтного коэффициента незначительно ухудшилось.(Средний коэффициент силуэта --  0.5349948060386395)

#### Статистический анализ получившихся кластеров

![image](https://user-images.githubusercontent.com/91901972/223784397-e7144849-078c-4d01-ae47-d35a5458d794.png)

Визуально  кластеры  немного отличаются друг от друга. Судя по графикам плотности, по показателю **petal_length** имеют различия, а по **sepal_length** и **sepal_width** имеют некоторые сходства. По диаграммам разброса видно, что оба кластера образуют не совсем плотное множество точек, разбиение нестрогое.

#### Оценка точности кластеризации с помощью Acc, сравнив оценки с фактическим разбиением на группы.

Acc для выборки с двумя показателями(sepal length (cm) petal length (cm)):
1) для разбиения на 2 кластера (Accuracy: 0.64)
2) для разбиения на 3 кластера (Accuracy: 0.88)
3) для разбиения на 4 кластера (Accuracy: 0.63)

Из оценки кластеризации следует, что алгоритм(для 3-ёх кластеров) достиг высокой точности в своей работе, указывая правильную категоризацию большинства объектов данных.

Acc для выборки с двумя показателями(sepal length (cm) petal length (cm)):
1) для разбиения на 2 кластера (Accuracy: 0.67)
2) для разбиения на 3 кластера (Accuracy: 0.453)
3) для разбиения на 4 кластера (Accuracy: 0.446)

Из оценки кластеризации следует, что алгоритм(при разбиении на 2 кластера) достиг высокой точности в своей работе, указывая правильную категоризацию большинства объектов данных.



