{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка пакетов\n",
    "import numpy as np\n",
    "import random\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from pandas import DataFrame\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "#-------Генерация исходных данных---------\n",
    "\n",
    "# задаём ядро генератора случайных чисел\n",
    "np.random.seed(10111)\n",
    "\n",
    "# всего наблюдений, доля обучающей выборки\n",
    "n_all, train_percent = 60, 0.85\n",
    "\n",
    "# параметры распределения X\n",
    "x_min, x_max = 5, 105\n",
    "\n",
    "# генерируем X (uniform - равномерное распределение)\n",
    "x = np.random.uniform(x_min, x_max, n_all)\n",
    "# генерируем случайный шум\n",
    "mu, sigma = 0,1\n",
    "res = np.random.normal(mu, sigma, n_all)\n",
    "\n",
    "# отбираем наблюдения в обучающую выборку (без повторений значений)\n",
    "in_train = np.random.choice(np.arange(n_all), int(n_all*train_percent), replace=False)\n",
    "\n",
    "# истинная функция взаимосвязи\n",
    "## можно перенести вверх\n",
    "def y_func (x) :\n",
    "    return(4 - 2e-02*x + 5.5e-03*x**2 - 4.9e-05*x**3)\n",
    "    \n",
    "# для графика истинной взаимосвязи\n",
    "# возвращает массив со всеми значениями х\n",
    "x_line = np.linspace(x_min, x_max, n_all)\n",
    "y_line = y_func(x_line)\n",
    "\n",
    "# фактические значения y (с шумом)\n",
    "y = y_func(x)+res\n",
    "\n",
    "# создаём векторы с данными для построения графиков\n",
    "# наблюдения на обучающей выборке\n",
    "x_train = x[in_train]\n",
    "y_train = y[in_train]\n",
    "\n",
    "# наблюдения на тестовой выборке\n",
    "x_test = np.delete(x,in_train)\n",
    "y_test = np.delete(y,in_train)\n",
    "\n",
    "\n",
    "#-----------------------------------------\n",
    "#-------Графики---------\n",
    "\n",
    "# график 1: исходные данные\n",
    "# обучающая выборка\n",
    "plt.scatter(x_train, y_train, color='black', label='обучение', alpha=0.6)\n",
    "#  тестовая выборка\n",
    "plt.scatter(x_test, y_test, color='red', label='тест', alpha=0.6)\n",
    "#  истинная функция взаимосвязи\n",
    "plt.plot(x_line, y_line, color='black', linestyle='dashed', label='f(X)')\n",
    "#  подписи осей\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "#  легенда\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "'''\n",
    "#-----------------------------------------\n",
    "#-------Сплайны---------\n",
    "\n",
    "# модель натурального сплайна с заданным количеством узлов (df)\n",
    "my_df = 38\n",
    "\n",
    "# сохраняем индексы отсортированного по возрастанию x из обучающей выборки\n",
    "x_sorted_index = sorted(range(len(x_train)), key=lambda k: x_train[k])\n",
    "\n",
    "# равноотстоящие координаты по X для прорисовки сглаженной кривой\n",
    "x_train_lin = np.linspace(min(x_train), max(x_train), num=300, endpoint=True)\n",
    "\n",
    "# создаём из данных объекты, понятные R\n",
    "r_x = robjects.FloatVector(x_train)\n",
    "r_y = robjects.FloatVector(y_train)\n",
    "\n",
    "# импортируем нужную функцию из R\n",
    "r_smooth_spline = robjects.r['smooth.spline']\n",
    "\n",
    "# строим сглаживающий сплайн\n",
    "fit = r_smooth_spline(x=r_x, y=r_y, df=my_df)\n",
    "\n",
    "# делаем прогнозы\n",
    "y_hat_train = np.array(robjects.r['predict'](fit, \n",
    "    robjects.FloatVector(x_train)).rx2('y'))\n",
    "y_hat_test = np.array(robjects.r['predict'](fit, \n",
    "    robjects.FloatVector(x_test)).rx2('y'))\n",
    "y_lin_plot = np.array(robjects.r['predict'](fit, \n",
    "    robjects.FloatVector(x_train_lin)).rx2('y'))\n",
    "\n",
    "# строим график\n",
    "plt.plot(x_train, y_train, color='black', ls='', marker='.', label='обучение')\n",
    "plt.plot(x_line, y_line, color='black', ls='dashed', marker='', label='f(X)')\n",
    "plt.plot(x_train_lin, y_lin_plot, marker='', label='сплайн с df = %s' % my_df)\n",
    "plt.plot(x_test, y_test, color='red', ls='', marker='.', label='тест факт')\n",
    "plt.plot(x_test, y_hat_test, color='red', ls='', marker='+', label='тест прогноз')\n",
    "#  подписи осей\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "# легенда\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# считаем MSE\n",
    "MSE_fit = [sum((y_train - y_hat_train)**2) / len(y_train),\n",
    "sum((y_test - y_hat_test)**2) / len(y_test)]\n",
    "\n",
    "# выводим MSE с округлением\n",
    "print(np.around(MSE_fit, 2))\n",
    "\n",
    "#  Теперь строим модели с df от 2 до 40 ########################################\n",
    "\n",
    "# максимальное число степеней свободы для модели сплайна\n",
    "max_df = 40\n",
    "\n",
    "# фрейм данных для сохранения MSE на обучающей и на тестовой \n",
    "#  при разных степенях свободы\n",
    "MSE_all_dfs = [[0] * 2 for i in range(2, max_df+1)]\n",
    "MSE_all_dfs = DataFrame(MSE_all_dfs, columns=['MSE_train', 'MSE_test'],\n",
    "                       index=list(range(2, max_df+1)))\n",
    "\n",
    "# заполняем фрейм\n",
    "for i_df in range(2, max_df+1) :\n",
    "    \n",
    "    # обучаем модель\n",
    "    fit = r_smooth_spline(x=r_x, y=r_y, df=i_df)\n",
    "    \n",
    "    # прогноз на обучающей выборке\n",
    "    y_train_hat = np.array(robjects.r['predict'](fit, \n",
    "        robjects.FloatVector(x_train)).rx2('y'))\n",
    "    # прогноз на тестовой выборке\n",
    "    y_test_hat = np.array(robjects.r['predict'](fit, \n",
    "        robjects.FloatVector(x_test)).rx2('y'))\n",
    "    \n",
    "    # считаем MSE\n",
    "    MSE_all_dfs.loc[i_df, 'MSE_train'] = sum((y_train - y_train_hat)**2) / len(y_train_hat)\n",
    "    MSE_all_dfs.loc[i_df, 'MSE_test'] = sum((y_test - y_test_hat)**2) / len(y_test_hat)\n",
    "\n",
    "\n",
    "# фильтруем таблицу по минимальной MSE на тестовой выборке\n",
    "print(MSE_all_dfs[MSE_all_dfs['MSE_test'] == min(MSE_all_dfs['MSE_test'])])\n",
    "\n",
    "# график изменения MSE с увеличением df\n",
    "plt.plot(MSE_all_dfs.index, MSE_all_dfs['MSE_train'], color='dimgrey', \n",
    "         marker='', label='обучение')\n",
    "plt.plot(MSE_all_dfs.index, MSE_all_dfs['MSE_test'], color='red', \n",
    "         marker='', label='тест')\n",
    "plt.plot([2, 2], [MSE_all_dfs.iloc[0]['MSE_train'], MSE_all_dfs.iloc[0]['MSE_test']],\n",
    "         ls='', marker='s', label='df=2')\n",
    "plt.plot([6, 6], [MSE_all_dfs.iloc[4]['MSE_train'], MSE_all_dfs.iloc[4]['MSE_test']],\n",
    "         ls='', marker='s', label='df=6')\n",
    "plt.plot([38, 38], [MSE_all_dfs.iloc[36]['MSE_train'], MSE_all_dfs.iloc[36]['MSE_test']],\n",
    "         ls='', marker='s', label='df=38')\n",
    "plt.hlines(1, 0, 40, linestyles='dashed', color='grey', label='Var(e)=1')\n",
    "#  подписи осей\n",
    "plt.xlabel('степени свободы (df)')\n",
    "plt.ylabel('MSE')\n",
    "# легенда\n",
    "plt.legend(loc='best')\n",
    "\"\"\"\n",
    "Кривая MSE на обучающей выборке стабильно снижается с ростом узлов сплайна.\n",
    "Чем больше наблюдений, через которые прошёл сплайн, тем точнее модель.\n",
    "Это говорит о переобучении.\n",
    "Лучшую модель следуют выбирать по минимуму на кривой MSE на тестовой выборке.\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
